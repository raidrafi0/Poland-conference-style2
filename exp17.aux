\relax 
\citation{Grigore2000Reinforcement,Cohen2010Reinforcement,Liu2004Reinforcement,Supancic2017Tracking}
\citation{Jinlin2009Neurofuzzy}
\citation{Sootla2013On}
\citation{Hall2011Reinforcement}
\citation{Wei2015Reinforcement}
\citation{Perot2017End}
\citation{Yun2017Action,Yun2018Action}
\@writefile{toc}{\contentsline {title}{Road Tracking Using Deep Reinforcement Learning for Self-Driving Car Applications\unskip {}}{1}}
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Raid Rafi Omar Al-Nima, Tingting Han, and Taolue Chen}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{Grigore2000Reinforcement}
\citation{Cohen2010Reinforcement}
\citation{Liu2004Reinforcement}
\citation{Supancic2017Tracking}
\citation{Ros2016TheSYNTHIA}
\citation{Ros2016TheSYNTHIA}
\@writefile{toc}{\contentsline {paragraph}{Related work.}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Modelling}{2}}
\@writefile{toc}{\contentsline {paragraph}{The dataset.}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Road Tracking}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The suggested front view road tracking zones, lines and anchor point}}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:segmentation_regions1}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Actions codes}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Segmented images for road tracking: (a) straightforward, (b) turning left, (c) turning right, (d) reverse or backward, (e-g) stopping action because of a single crossing object, (h-j) stopping action because of two crossing objects and (k) stopping action because of three crossing objects}}{4}}
\newlabel{Fig:segmentation}{{\caption@xref {Fig:segmentation}{ on input line 140}}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Policy search}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Proposed DRL-RT}{4}}
\citation{Ros2016TheSYNTHIA}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The main design of the proposed DRL-RT. It consists of two conventional layers, two ReLU layers, a pooling layer, a fully connected layer, a regression layer and a classification layer}}{5}}
\newlabel{Fig:Deep_Reinf_Net}{{3}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Databases}{5}}
\citation{kingma2014adam}
\citation{kingma2014adam}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Examples of the four employed environments}}{6}}
\newlabel{Table:Environments_Examples}{{1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Training stage}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The training performance of the DRL-RT for the: (1) spring environment, (2) fog environment, (3) rain environment and (4) heavy-rain environment}}{7}}
\newlabel{fig:training_curves}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Testing stage}{7}}
\citation{Karaduman2017Deep}
\citation{bojarski2016end}
\citation{George2016Real}
\citation{Yun2017Action,Yun2018Action}
\citation{mnih2015human}
\citation{Karaduman2017Deep}
\citation{bojarski2016end}
\citation{George2016Real}
\citation{Yun2017Action,Yun2018Action}
\citation{Karaduman2017Deep}
\citation{bojarski2016end}
\citation{George2016Real}
\citation{Yun2017Action,Yun2018Action}
\citation{mnih2015human}
\citation{arulkumaran2017brief}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The performance of the DRL-RT under different employed environments}}{8}}
\newlabel{fig:Main_Results}{{5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Comparisons}{8}}
\bibstyle{IEEEtr}
\bibdata{references14}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces A comparison between our proposed DRL-RT method and other suggested networks}}{9}}
\newlabel{Table:Comparisons}{{2}{9}}
\bibcite{Grigore2000Reinforcement}{1}
\bibcite{Cohen2010Reinforcement}{2}
\bibcite{Liu2004Reinforcement}{3}
\bibcite{Supancic2017Tracking}{4}
\bibcite{Jinlin2009Neurofuzzy}{5}
\bibcite{Sootla2013On}{6}
\bibcite{Hall2011Reinforcement}{7}
\bibcite{Wei2015Reinforcement}{8}
\bibcite{Perot2017End}{9}
\bibcite{Yun2017Action}{10}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{10}}
\bibcite{Yun2018Action}{11}
\bibcite{Ros2016TheSYNTHIA}{12}
\bibcite{kingma2014adam}{13}
\bibcite{Karaduman2017Deep}{14}
\bibcite{bojarski2016end}{15}
\bibcite{George2016Real}{16}
\bibcite{mnih2015human}{17}
\bibcite{arulkumaran2017brief}{18}
