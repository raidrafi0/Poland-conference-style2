\relax 
\citation{Grigore2000Reinforcement}
\citation{Cohen2010Reinforcement}
\citation{Liu2004Reinforcement}
\citation{Supancic2017Tracking}
\@writefile{toc}{\contentsline {title}{Road Tracking Using Deep Reinforcement Learning for Driving Cars Applications}{1}}
\@writefile{toc}{\authcount {2}}
\@writefile{toc}{\contentsline {author}{Raid Rafi Omar Al-Nima, Tingting Han, and Taolue Chen}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{Jinlin2009Neurofuzzy}
\citation{Hall2011Reinforcement}
\citation{Sootla2013On}
\citation{Wei2015Reinforcement}
\citation{Perot2017End}
\citation{Yun2017Action}
\citation{Yun2018Action}
\citation{Grigore2000Reinforcement}
\citation{Cohen2010Reinforcement}
\citation{Liu2004Reinforcement}
\citation{Supancic2017Tracking}
\citation{Jinlin2009Neurofuzzy}
\citation{Sootla2013On}
\citation{Hall2011Reinforcement}
\citation{Wei2015Reinforcement}
\citation{Yun2017Action,Yun2018Action}
\citation{Ros2016TheSYNTHIA}
\@writefile{toc}{\contentsline {section}{\numberline {2}Modelling}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The suggested front view road tracking zones, lines and anchor point}}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:segmentation_regions1}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The road tracking motivations of segmented images: (a) the straight forward direction, (b) turning left direction, (c) turning right direction, (d) reverse or backward direction, (e-g) stopping action because of a single crossing object, (h-j) stopping action because of two crossing objects and (k) stopping action because of three crossing objects}}{3}}
\newlabel{Fig:segmentation}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Road Tracking:}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The main design of the proposed DRL-RT. It consists of two conventional layers, two ReLU layers, a pooling layer, a fully connected layer, a regression layer and a classification layer}}{4}}
\newlabel{Fig:Deep_Reinf_Net}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Actions codes:}{4}}
\citation{koren2001computer}
\citation{Arulkumaran2017Deep}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The road tracking actions with their suggested codes and descriptions}}{5}}
\newlabel{Table:Signs_codes}{{1}{5}}
\citation{arulkumaran2017brief}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Policy search:}{6}}
\newlabel{Eq:MDP}{{1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Proposed DRL-RT:}{6}}
\citation{omar2018deep}
\citation{simo2016learning}
\citation{krizhevsky2012imagenet}
\citation{wu2017introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Theoretical concepts:}{7}}
\newlabel{eq:conv_layer}{{2}{7}}
\newlabel{eq:relu_layer}{{3}{7}}
\newlabel{eq:pooling_layer}{{4}{7}}
\citation{stutz2014neural}
\citation{saugirouglu2009intelligent}
\citation{Ros2016TheSYNTHIA}
\citation{kingma2014adam}
\newlabel{eq:fully_connect}{{5}{8}}
\newlabel{eq:fully_connect}{{6}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Databases:}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Examples of the four employed environments}}{9}}
\newlabel{Table:Environments_Examples}{{2}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Training stage:}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Testing stage:}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The training performance of the DRL-RT for the: (1) spring environment, (2) fog environment, (3) rain environment and (4) heavy-rain environment}}{10}}
\newlabel{fig:training_curves}{{4}{10}}
\citation{Karaduman2017Deep}
\citation{bojarski2016end}
\citation{George2016Real}
\citation{Yun2017Action,Yun2018Action}
\citation{mnih2015human}
\citation{Karaduman2017Deep}
\citation{bojarski2016end}
\citation{George2016Real}
\citation{Yun2017Action,Yun2018Action}
\citation{mnih2015human}
\citation{arulkumaran2017brief}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The performance of the DRL-RT under different employed environments}}{11}}
\newlabel{fig:Main_Results}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Comparisons:}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces A comparison between our proposed DRL-RT method and other suggested networks}}{11}}
\newlabel{Table:Comparisons}{{3}{11}}
\bibstyle{IEEEtr}
\bibdata{references14}
\bibcite{Grigore2000Reinforcement}{1}
\bibcite{Cohen2010Reinforcement}{2}
\bibcite{Liu2004Reinforcement}{3}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{12}}
\bibcite{Supancic2017Tracking}{4}
\bibcite{Jinlin2009Neurofuzzy}{5}
\bibcite{Hall2011Reinforcement}{6}
\bibcite{Sootla2013On}{7}
\bibcite{Wei2015Reinforcement}{8}
\bibcite{Perot2017End}{9}
\bibcite{Yun2017Action}{10}
\bibcite{Yun2018Action}{11}
\bibcite{Ros2016TheSYNTHIA}{12}
\bibcite{koren2001computer}{13}
\bibcite{Arulkumaran2017Deep}{14}
\bibcite{arulkumaran2017brief}{15}
\bibcite{omar2018deep}{16}
\bibcite{simo2016learning}{17}
\bibcite{krizhevsky2012imagenet}{18}
\bibcite{wu2017introduction}{19}
\bibcite{stutz2014neural}{20}
\bibcite{saugirouglu2009intelligent}{21}
\bibcite{kingma2014adam}{22}
\bibcite{Karaduman2017Deep}{23}
\bibcite{bojarski2016end}{24}
\bibcite{George2016Real}{25}
\bibcite{mnih2015human}{26}
